{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SERVIR/flood_mapping_intercomparison/blob/main/hydrafloods/training_materials/oct_2021_hf_training/notebooks/remote_sensing_water_day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uhp7yq0Vm5f"
      },
      "source": [
        "# Introduction to remote sensing of surface water using HYDRAFloods\n",
        "\n",
        "In this notebook we will look at basic functionality of HYDRAFloods and how to create surface water maps from different sensors. Lastly we will explore the  Full documentation and additional examples for the HYDRAFloods Python package can be found at: https://servir-mekong.github.io/hydra-floods/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkFfcO7VXAz2"
      },
      "source": [
        "## Setup\n",
        "Before running the notebook, please mount your Google Drive to the notebook. We will use Google Drive to securely store Earth Engine credentials for use in other notebooks. This will allow us to bypass authenticating everytime saving time throughout the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziceyoy7TcgY"
      },
      "source": [
        "# mount the google drive so that we can save credentials\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbaUimiCXOe7"
      },
      "source": [
        "Now we will install the `hydrafloods` package for surface water mapping and `geemap` for interactive viewing results from Earth Engine.\n",
        "\n",
        "You will get and error stating \"*You must restart the runtime in order to use newly installed versions.*\" This can be ignored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJlHZoltToUp"
      },
      "source": [
        "# install the packages needed\n",
        "!pip install hydrafloods geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs_6nhrrv7SS"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JbcwG-YTpA7"
      },
      "source": [
        "import ee\n",
        "import datetime\n",
        "import hydrafloods as hf\n",
        "import geemap.eefolium as geemap\n",
        "import geemap.colormaps as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql0PoJ0vv9mC"
      },
      "source": [
        "Check the HYDRAFloods package version, should be \"2021.10.11\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzotc6UvzPbv"
      },
      "source": [
        "hf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVdSf3MuTq1D"
      },
      "source": [
        "# initiate authentication workflow\n",
        "# it will ask to authenticate if no credentials are available\n",
        "# will also initialize ee session\n",
        "_ = geemap.Map()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PL0_JI7XF9v"
      },
      "source": [
        "## Exploring HYDRAFloods Datasets\n",
        "The start of any process is to acquire data. Here HYDRAFloods is used to connect to Earth Engine collections and apply spatio-temporal filters of our interest with minimal amount of coding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqhlxVREbqTn"
      },
      "source": [
        "region = hf.country_bbox(\"Guatemala\")\n",
        "start_time = \"2019-01-01\"\n",
        "end_time = \"2019-07-01\"\n",
        "\n",
        "# get a Landsat 8 collection\n",
        "lc8 = hf.Landsat8(region,start_time,end_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODETO7TCwUPo"
      },
      "source": [
        "print(lc8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvEw0Aq6wVu5"
      },
      "source": [
        "lc8.n_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAQwKVLDwX4e"
      },
      "source": [
        "lc8.dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioz6WdiSwbK1"
      },
      "source": [
        "lc8.collection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xEm6s9iwo6Z"
      },
      "source": [
        "`hydrafloods` has specialized datasets classes that extend a hydrafloods Dataset class and are common image collections used in surface water mapping (See list [here](https://servir-mekong.github.io/hydra-floods/using-datasets/#specialized-datasets)). These specialized datasets include a custom `qa()` method based on quality assessment bands that gets called on initialization to mask poor quality pixels and custom methods that make harmonization easy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOxUBwPMxYTg"
      },
      "source": [
        "To demonstrate, we will pull the imagery from the Lansat 8 dataset with and without the qa process and compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0EADHHBxouh"
      },
      "source": [
        "lc8_noqa = hf.Landsat8(region,start_time,end_time,use_qa=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og7kH6GDwhmH"
      },
      "source": [
        "first_qa = lc8.collection.first()\n",
        "first_noqa = lc8_noqa.collection.first()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3grbK0S3mtJA"
      },
      "source": [
        "first_qa.bandNames().getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vffN_H7SxDTI"
      },
      "source": [
        "optical_vis = {\n",
        "    \"min\":50,\n",
        "    \"max\":5500,\n",
        "    \"bands\":\"swir2,nir,green\",\n",
        "    \"gamma\":1.5,\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhRMdCew8Xv"
      },
      "source": [
        "Map = geemap.Map(center=(15.5754, -89.8297), zoom=8)\n",
        "\n",
        "Map.addLayer(first_qa,optical_vis, 'Landsat 8 (QA)')\n",
        "Map.addLayer(first_noqa,optical_vis, 'Landsat 8 (No QA)')\n",
        "\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ugSpFNmxbZa"
      },
      "source": [
        "Again, the quality masking is turned on by default for *all* data and helps with quickly accessing and processing data.\n",
        "\n",
        "One last note, the optical sensor bands are automatically renamed to a common scheme so that they can be used together easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVPSxWAeb1TD"
      },
      "source": [
        "## Optical surface water mapping\n",
        "Optical data has a long history of being used for surface water mapping and is used for long-term studies (i.e. [Pekel et al., 2016](https://www.nature.com/articles/nature20584), [Donchyts et al., 2016](https://www.nature.com/articles/nclimate3111)). With optical imagery, there are a few steps usually completed for accurate surface water maps:\n",
        "\n",
        "1. Acquire data\n",
        "2. Calibration/georegistration\n",
        "3. Atmospheric correction\n",
        "4. Cloud/shadow masking\n",
        "5. Terrain Correction (optional)\n",
        "6. Calculate water index\n",
        "7. Map water\n",
        "\n",
        "Earth Engine has taken care of steps 1-3 for some optical datasets so we can directly access analysis ready surface refelctance data. These subsequent steps are fairly general and there are multiple paths we can take to achieve the goal of surface water maps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51qst973nN9"
      },
      "source": [
        "Here we are going to get a Landsat 8 dataset again for Guatemala and create a monthly water maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYeY8LXob0tz"
      },
      "source": [
        "region = hf.country_bbox(\"Guatemala\")\n",
        "start_time = \"2019-01-01\"\n",
        "end_time = \"2019-06-01\"\n",
        "\n",
        "# get a Landsat 8 collection\n",
        "lc8 = hf.Landsat8(region,start_time,end_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtthWaEo348C"
      },
      "source": [
        "To classify water within optical imagery, it is common practice to calculate a water index. There are many water indices and selection of an index should be based on your use case; here is a paper describing and comparing common indices: https://doi.org/10.3390/w9040256\n",
        "\n",
        "For this case we will use the modified normalized water index ([Xu, 2006](https://doi.org/10.1080/01431160600589179)). In `hydrafloods` the water index functions are named based on their common abbreviation so we can simply call it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcwY-mY-3dTx"
      },
      "source": [
        "# calculate water index\n",
        "# here we calculate the modified normalized water index\n",
        "water_index = lc8.apply_func(hf.mndwi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4UqOMKW4tJo"
      },
      "source": [
        "first_img = lc8.collection.first()\n",
        "first_mndwi = water_index.collection.first()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JaeywF64_jT"
      },
      "source": [
        "wi_vis ={\n",
        "    \"bands\":\"mndwi\",\n",
        "    \"min\": -0.5,\n",
        "    \"max\":0.5,\n",
        "    \"palette\": cm.palettes.Blues\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVuxNBWO48iV"
      },
      "source": [
        "Map = geemap.Map(center=(15.5754, -89.8297), zoom=8)\n",
        "\n",
        "Map.addLayer(first_qa,optical_vis, 'Landsat 8')\n",
        "Map.addLayer(first_mndwi,wi_vis, 'Landsat 8 MNDWI')\n",
        "\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIJ2_flc6Hax"
      },
      "source": [
        "water = water_index.apply_func(hf.edge_otsu, initial_threshold=0.0, edge_buffer=300, scale=150, invert=True,thresh_no_data=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScL9nqEO6Yf2"
      },
      "source": [
        "first_water = water.collection.first()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wt29t16ctC"
      },
      "source": [
        "Map = geemap.Map(center=(15.5754, -89.8297), zoom=8)\n",
        "\n",
        "Map.addLayer(first_qa,optical_vis, 'Landsat 8')\n",
        "Map.addLayer(first_mndwi,wi_vis, 'Landsat 8 MNDWI')\n",
        "Map.addLayer(first_water.selfMask(),{\"min\":0,\"max\":1,\"palette\":cm.palettes.Blues}, 'Landsat 8 Water')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUsqPQEBI_ij"
      },
      "source": [
        "monthly_mosaics = lc8.aggregate_time(\n",
        "    dates=[f\"2019-{i:02d}-01\" for i in range(1,7)], # define times for 1st of every month in collection\n",
        "    period_unit=\"month\", # specify that the aggregation should be 1 month\n",
        "    reducer=ee.Reducer.median() # reduce to the median observation per pixel\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-Y13at7IpJ"
      },
      "source": [
        "monthly_water = water.aggregate_time(\n",
        "    dates=[f\"2019-{i:02d}-01\" for i in range(1,7)], # define times for 1st of every month in collection\n",
        "    period_unit=\"month\", # specify that the aggregation should be 1 month\n",
        "    reducer=ee.Reducer.mode() # reduce the mode observation per pixel\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVyvE94N7VeD"
      },
      "source": [
        "monthly_water.dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6QLo4pT8I51"
      },
      "source": [
        "Map = geemap.Map(center=(15.5754, -89.8297), zoom=8)\n",
        "\n",
        "Map.addLayer(monthly_mosaics.collection.first(), optical_vis, 'Jan. Landsat 8 Mosaic')\n",
        "Map.addLayer(monthly_water.collection.first().selfMask(),{\"min\":0,\"max\":1,\"palette\":cm.palettes.Blues}, 'Jan. Landsat 8 Water')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDZ6MQkabqjo"
      },
      "source": [
        "## SAR surface water mapping\n",
        "Synthetic Aperture Radar (SAR) data is often used to map surface water due to the unique ability to sense information of the land even in the presence of clouds. As with optical imagery, there are a few steps for accurate surface water maps from SAR imagery including:\n",
        "\n",
        "1. Acquire data\n",
        "2. Calibration/georegistration\n",
        "3. Terrain Correction\n",
        "4. Speckle Filter\n",
        "5. Map water\n",
        "\n",
        "Earth Engine has taken care of steps 1-2 so we can directly access anlysis ready data. These subsequent steps are fairly general and there are multiple algorithms that can achieve each step to create high quality water maps from SAR. We will explore one workflow implemented with the hydrafloods package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NbXbgGqbvsy"
      },
      "source": [
        "# define a location geometry\n",
        "region = hf.country_bbox(\"Guatemala\")\n",
        "\n",
        "# define time period\n",
        "start_time = \"2020-11-04\"\n",
        "end_time = \"2020-11-05\"\n",
        "\n",
        "# get the Sentinel 1 collection as a hydrafloods Dataset\n",
        "s1 = hf.Sentinel1(region,start_time,end_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GljoH20s9DDh"
      },
      "source": [
        "# inspect the dataset object\n",
        "s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLSlKWg9PjN"
      },
      "source": [
        "# print how many images we have for our specified time and location\n",
        "s1.n_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAw4O6n89SWC"
      },
      "source": [
        "# get the imagery acquisition times\n",
        "s1.dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhsHI4C-9YOG"
      },
      "source": [
        "merit = ee.Image(\"MERIT/Hydro/v1_0_1\")\n",
        "\n",
        "# extract out the DEM and HAND bands\n",
        "dem = merit.select(\"elv\").unmask(0)\n",
        "hand = merit.select(\"hnd\").unmask(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQUoxlaA9cW1"
      },
      "source": [
        "# apply a (psuedo-) terrain flattening algorithm to S1 data\n",
        "s1_flat = s1.apply_func(hf.slope_correction, elevation = dem, buffer = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLuJcr7s9e4i"
      },
      "source": [
        "# apply a speckle filter algorithm to S1 data\n",
        "s1_filtered = s1_flat.apply_func(hf.gamma_map)\n",
        "\n",
        "# aggregate SAR observations to 30x30 m pixels\n",
        "s1_aggregated = s1_filtered.apply_func(lambda x: x.focal_mean(1.5).reproject(ee.Projection(\"EPSG:4326\").atScale(30)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taFok0Ok9vJU"
      },
      "source": [
        "# view the results of SAR water mapping\n",
        "Map = geemap.Map(center=(16.0029, -90.5109), zoom=12)\n",
        "\n",
        "Map.addLayer(s1.collection.median(),{\"bands\": \"VV\", \"min\":-25, \"max\": 0}, 'Sentinel 1')\n",
        "Map.addLayer(s1_flat.collection.median(),{\"bands\": \"VV\", \"min\":-25, \"max\": 0}, 'Sentinel 1 (terrain flattened)')\n",
        "Map.addLayer(s1_aggregated.collection.median(),{\"bands\": \"VV\", \"min\":-25, \"max\": 0}, 'Sentinel 1 (speckle filtered)')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08IhVN9C9hAT"
      },
      "source": [
        "# apply a water thresholding algorithm to the collection\n",
        "# method from Markert et al., 2020 (https://doi.org/10.3390/rs12152469)\n",
        "water = s1_filtered.apply_func(hf.edge_otsu,initial_threshold=-14,band=\"VV\",edge_buffer=300,scale=180)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMUhg8s0sZZn"
      },
      "source": [
        "water_hand = water.collection.mode().And(hand.lt(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOJaWi729r-B"
      },
      "source": [
        "# view the results of SAR water mapping\n",
        "Map = geemap.Map(center=(16.0029, -90.5109), zoom=12)\n",
        "\n",
        "Map.addLayer(s1.collection.median(),{\"bands\": \"VV\", \"min\":-25, \"max\": 0}, 'Sentinel 1')\n",
        "Map.addLayer(water.collection.mode(),{\"min\":0,\"max\":1,\"palette\":cm.palettes.Blues}, \"Sentinel 1 (water)\")\n",
        "Map.addLayer(water_hand,{\"min\":0,\"max\":1,\"palette\":cm.palettes.Blues}, \"Sentinel 1 (water hand masked)\")\n",
        "\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtNUqmzKuC0R"
      },
      "source": [
        "hf.export_image(water.collection.mode(), region, scale=30, crs='EPSG:4326', pyramiding={\".default\":\"mode\"}, export_type='toDrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrRU_OBQ_SZL"
      },
      "source": [
        "## Advanced water mapping\n",
        "\n",
        "What we have covered at this point is has been relatively straighforward water mapping using adaptive thresholding techniques. This are efficient and produce adequate results, however, are not always the most accurate or appropriate. Here we will cover more advanced water mapping techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inap2EfQCM9J"
      },
      "source": [
        "### ML based water mapping\n",
        "\n",
        "Some studies have successfully employed machine learning workflows for surface water mapping such as [Huang et al., 2018](https://doi.org/10.3390/rs10050797). There are ML based workflows implemented in `hydrafloods` to make the processing easier for users. In this case we will implement methods from [Cordeiro et al., 2021](https://doi.org/10.1016/j.rse.2020.112209) but for Sentinel 1 imagery."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtqGsHLqIPCk"
      },
      "source": [
        "First we will create a stack of images with multiple bands that we will use as input features for the ML model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfsxCb5H_X29"
      },
      "source": [
        "# use add indices to calculate multiple indices at onces efficiently\n",
        "s1_multiband = s1_filtered.apply_func(hf.add_indices,indices=[\"vv_vh_ratio\",\"ndpi\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL4aM3DYAGjU"
      },
      "source": [
        "# reduce the multiple images into one as an input\n",
        "input_img = s1_multiband.collection.mosaic()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x-rtCBXIWxk"
      },
      "source": [
        "Here we apply the  algorithm. This will take the input bands and attempt to find *k* classes that describe a sample. The *k* classes will be ordered based on a ranking band (in this case VV). The class with the lowest centroid value of VV (i.e. minimum ranking) will be considered water, all other classes will be considered not-water. Then a final generalization model will be applied to find the probability that each pixel fits within the designated water class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw4rLtTMAQ_R"
      },
      "source": [
        "# apply an advanced water mapping algorithm to automatically calculate water probability\n",
        "water_proba = hf.multidim_semisupervised(\n",
        "    first_qa,\n",
        "    bands = [\"green\",\"red\",\"nir\",\"swir2\"],\n",
        "    rank_band=\"swir2\",\n",
        "    ranking='min',\n",
        "    # region=region,\n",
        "    n_samples=2500,\n",
        "    seed=7,\n",
        "    scale=120,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyIO1-LnAoPn"
      },
      "source": [
        "# view the results of SAR water mapping\n",
        "Map = geemap.Map(center=(16.0029, -90.5109), zoom=12)\n",
        "\n",
        "Map.addLayer(s1.collection.median(),{\"bands\": \"VV\", \"min\":-25, \"max\": 0}, 'Sentinel 1')\n",
        "Map.addLayer(water_proba,{\"min\":0,\"max\":1,\"palette\":cm.palettes.inferno}, \"Sentinel 1 (water proba)\")\n",
        "\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdAtQXS6HNJd"
      },
      "source": [
        "### Deep learning for water mapping\n",
        "\n",
        "---\n",
        "\n",
        "ðŸš¨ WARNING! ðŸš¨ This section requires you to be part of the \"*servir-ee-tf*\" group to use the following deep learning model.\n",
        "\n",
        "---\n",
        "\n",
        "Going one more step further, some studies have successfully employed deep learning for satellite image classification (i.e. [Hughes & Kennedy, 2019](https://doi.org/10.3390/rs11212591 )). In the referenced paper, they trained a fully convolutional neural network (FCNN) to predict quality classes in Landsat imagery. We have implemented a similar network to be used with Earth Engine where the model will predict Cloud, Shadow, Snow, Water, Clear, and No Data classes. We can then extract the water class and use this as a water map.\n",
        "\n",
        "This model is specifically for Landsat imagery. Deep learning models are sensitive to data inputs so use with caution for other sensors. Methods for this particular model are described in the following presentation: https://docs.google.com/presentation/d/1LOVJGxa_7bXfq2QCfrXSAvmE_C6rdSGDi4peamKNjxU/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVYrhybrHTNu"
      },
      "source": [
        "Here we will connect to the hosted model from Earth Engine. We define the cloud project, model name, model version, and a few more parameters then call `ee.Model.fromAiPlatformPredictor()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO-bwsuNGmYw"
      },
      "source": [
        "# set some ee.Model parameters\n",
        "PROJECT = 'ee-demos';\n",
        "MODEL_NAME = 'kel_cloud_model';\n",
        "VERSION_NAME = 'eeified_lsqa_vgg19unet_weighted';\n",
        "INSHAPES = ee.Dictionary({\"qa\":[6]});\n",
        "\n",
        "#Load the trained model and use it for prediction.\n",
        "model = ee.Model.fromAiPlatformPredictor(\n",
        "    projectName= PROJECT,\n",
        "    modelName= MODEL_NAME,\n",
        "    version= VERSION_NAME,\n",
        "    inputTileSize= [144,144],\n",
        "    inputOverlapSize= [8,8],\n",
        "    inputShapes= INSHAPES,\n",
        "    proj= ee.Projection('EPSG:4326').atScale(30),\n",
        "    fixInputProj= True,\n",
        "    outputBands= {'qa': {\n",
        "        'type': ee.PixelType.float(),\n",
        "        'dimensions': 1\n",
        "      }\n",
        "    }\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ZjdhxuHWHH"
      },
      "source": [
        "Now that we have our model and imagery, we can apply the prediction. Note that we use arrays to transfer data. These arrays need to be formatted in the exact way that is required for the model predictions. In this case it is height, width, bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhsY2FQVGns1"
      },
      "source": [
        "# apply prediction to image\n",
        "# rescale data to 0-1 and convert to Float Array for prediction\n",
        "predictions = model.predictImage(\n",
        "  first_noqa.multiply(0.0001).toFloat().toArray()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-WGKXpuHYHl"
      },
      "source": [
        "The output, `predictions`, is also an image formatted as an array where we can do some fun stuff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHU-LmfeHbWz"
      },
      "source": [
        "For starters, we can get the probability of each individual pixels belong to a class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpdMvEM6GsNK"
      },
      "source": [
        "# flatten predictions to class probabilities\n",
        "pred_probs = (\n",
        "    predictions\n",
        "    .arrayFlatten([['cloud','shadow','snow','water','land','nodata']])\n",
        "    .toFloat()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuLVJxu2HeN-"
      },
      "source": [
        "We can also calculate which class has the highest probablity and convert to a classified image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5TpOp7VGxYY"
      },
      "source": [
        "# flatten predictions to highest probability class\n",
        "pred_classes = (\n",
        "    predictions\n",
        "    .arrayArgmax()\n",
        "    .arrayFlatten([['qa']])\n",
        ")\n",
        "\n",
        "# mask land pixels so we are left with the interesting classes\n",
        "pred_classes = pred_classes.updateMask(pred_classes.neq(4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuLDfUKHG0F7"
      },
      "source": [
        "prob_vis = {\"bands\":\"water\",\"min\":0,\"max\":1}\n",
        "\n",
        "class_vis = {\n",
        "    \"min\":0,\n",
        "    \"max\":5,\n",
        "    \"palette\":'#ecf0f1,#7f8c8d,#00FFFF,#0000FF,#27ae60,#000000'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvWddsSSG1tC"
      },
      "source": [
        "Map = geemap.Map(center=(15.7962, -87.7849), zoom=12)\n",
        "\n",
        "Map.addLayer(first_noqa,optical_vis, \"Landsat 8 Image\")\n",
        "Map.addLayer(pred_probs,{\"bands\":\"water\",\"min\":0,\"max\":1},\"Water Probability\")\n",
        "Map.addLayer(pred_classes,class_vis,\"QA classes\")\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb_s8JW8HtU8"
      },
      "source": [
        "Deep learning can at the very least be an entire week long training by itself...this only serves and an example of how we can use deep learning for surface water mapping.\n",
        "\n",
        "An example notebooks for sampling, building/training, and deploying a your own deep learning model can be found here: https://github.com/gee-community/ee-tensorflow-notebooks/blob/master/landsat_qa_cnn/lc8_ee_qa_unet.ipynb"
      ]
    }
  ]
}