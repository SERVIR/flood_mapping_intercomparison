{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SERVIR/flood_mapping_intercomparison/blob/main/notebooks/Module_4_Sampling_Design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abofCC_dsGS_"
      },
      "source": [
        "#**Introduction**\n",
        "The goal of this notebook is to generate a set of point locations for our case study where we will validate the performance of each flood product/package based on high-resolution optical imagery. To do this, we need our flood maps from each product/package as well as our high-resolution optical imagery. We will conduct a clustered stratified sampling approach.\n",
        "\n",
        "## Step 1: Clustering\n",
        "\n",
        "Our first step is to cluster our area of interest. In this case, we will have one cluster that will consist of areas where **no** satellite has an obstructed view of the ground due to cloud cover, haze, or low quality data.\n",
        "\n",
        "\n",
        "For our optical flood maps, each of these maps comes with a cloud or low data quality mask. In Module 6, we assigned all of the maps the common value of 2 for this unusable data. We also want to mask out areas where our high-res optical data from Planet has clouds. We can use the Usable Data Mask (UDM) that comes with Planet data for this purpose.\n",
        "\n",
        "We will find the **union** of areas where each optical sensor has unusable data, and remove this union from the area of analysis.\n",
        "\n",
        "## Step 2: Stratification\n",
        "\n",
        "Stratification refers to the splitting of the area of interest into strata, which are groups of pixels that are both exhaustive and exlcusive. In other words, each pixel in the area of interest can be assigned to one and only one strata. In this case, we will use three classes of strata to investigate the performance of the flood products across various types of surface conditions. The three classes of strata we will use are land cover, elevation and slope\n",
        "\n",
        "\n",
        "### Step 2 Part 1: Land Cover\n",
        "\n",
        "We will use Google's Dynamic World Dataset [Brown et al 2022] to stratify the sampling area by Land Cover\n",
        "\n",
        "### Step 2 Part 2: Product Output\n",
        "\n",
        "We will use the output of the flood products themselves (i.e. water, nonwater) to evaluate the performance of the products by class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxb7X-hvMnLP"
      },
      "source": [
        "# Step 1: Define input Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the input variables below to suit your needs"
      ],
      "metadata": {
        "id": "ZWr7wm0PO3eQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNTJt6OPHjoG"
      },
      "outputs": [],
      "source": [
        "# Google Earth Engine Directory\n",
        "parent_directory = \"users/mickymags/cambodia_test/\"\n",
        "\n",
        "# Google Drive Folder\n",
        "my_gdrive_folder = 'Flood_Intercomparison'\n",
        "\n",
        "# Date of Interest\n",
        "doi = \"2024-10-01\"\n",
        "\n",
        "# Flood Event Description\n",
        "flood_event_desc='cambodia_20241001_test'\n",
        "\n",
        "# Google Earth Engine project\n",
        "my_gee_project = 'servir-sco-assets'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUzRKwOaHkJX"
      },
      "source": [
        "# Step 2: Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n07orLu6Mpt1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have not already installed geemap, uncomment the cell below."
      ],
      "metadata": {
        "id": "zNTv7HWEOyVw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0S42hk2Pfmp"
      },
      "outputs": [],
      "source": [
        "#!pip install geemap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLnwxSnQDwj"
      },
      "source": [
        "Now that we have installed our packages, it's time to import them via import so we can use them in this notebook. Below you can find a brief description of what each package does.\n",
        "\n",
        "The geemap package will allow us to visualize a Google Maps interface interactively within this notebook.\n",
        "The ee package will allow us to run Earth Engine functions via the python programming language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd19jRe_QAcA"
      },
      "outputs": [],
      "source": [
        "import geemap\n",
        "import ee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVjwxW_TQGms"
      },
      "source": [
        "In order to continue running this script, you need to be associated with a Google Cloud Project. Now, we have to authenticate and initialize earth engine. After you run the code below, click through the pop-up window to login to the Google Account associated with your Google Earth Engine account. Click \"Continue\" until you have returned to this notebook and a green checkmark appears to the left of the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znPXU49xQVzl"
      },
      "outputs": [],
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project = my_gee_project)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shqjPZZNSX5m"
      },
      "source": [
        "Import the Outputs from the previous modules:\n",
        "\n",
        "\n",
        "\n",
        "*   The Planet Imagery Usable Data Masks\n",
        "*   Each Flood Map\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODIFIABLE VARIABLE ALERT"
      ],
      "metadata": {
        "id": "aMdSFPVdw6E7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkBy4ugIQepQ"
      },
      "outputs": [],
      "source": [
        "aoi = ee.FeatureCollection(parent_directory + \"aoi\")\n",
        "aoi_centroid = aoi.geometry().centroid()             # Get the center of the AOI\n",
        "lon = aoi_centroid.coordinates().get(0).getInfo()    # Extract the longitude from the centroid\n",
        "lat = aoi_centroid.coordinates().get(1).getInfo()    # Extract the latitude from the centroid\n",
        "\n",
        "#Enter in the path to your planet imagery and Planet UDMS below. You can also use imagery other than Planet.\n",
        "\n",
        "pl_rg1_pt1 = ee.Image(parent_directory + \"reference_v2/planet_region1_8b_part1\")\n",
        "pl_rg1_pt2 = ee.Image(parent_directory + \"reference_v2/planet_region1_8b_part2\")\n",
        "pl_rg1_pt3 = ee.Image(parent_directory + \"reference_v2/planet_region1_8b_part3\")\n",
        "pl_rg2 = ee.Image(parent_directory + \"reference_v2/planet_region2_8b\")\n",
        "pl_rg3 = ee.Image(parent_directory + \"reference_v2/planet_region3_8b\")\n",
        "\n",
        "pl_mos = ee.ImageCollection([pl_rg1_pt1, pl_rg1_pt2, pl_rg1_pt3, pl_rg2, pl_rg3]).mosaic()\n",
        "\n",
        "pl_udm_pt1 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt1\")\n",
        "pl_udm_pt2 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt2\")\n",
        "pl_udm_pt3 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt3\")\n",
        "pl_udm_pt4 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt4\")\n",
        "pl_udm_pt5 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt5\")\n",
        "pl_udm_pt6 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt6\")\n",
        "pl_udm_pt7 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt7\")\n",
        "pl_udm_pt8 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt8\")\n",
        "pl_udm_pt9 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt9\")\n",
        "pl_udm_pt10 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt10\")\n",
        "pl_udm_pt11 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt11\")\n",
        "pl_udm_pt12 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt12\")\n",
        "pl_udm_pt13 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt13\")\n",
        "pl_udm_pt14 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt14\")\n",
        "pl_udm_pt15 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt15\")\n",
        "pl_udm_pt16 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt16\")\n",
        "pl_udm_pt17 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt17\")\n",
        "pl_udm_pt18 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt18\")\n",
        "pl_udm_pt19 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt19\")\n",
        "pl_udm_pt20 = ee.Image(\"users/mickymags/flood_intercomparison_chad_09_26_take2/reference_v2/pl_udm_pt20\")\n",
        "\n",
        "pl_udm_ic = ee.ImageCollection([pl_udm_pt1, pl_udm_pt2, pl_udm_pt3, pl_udm_pt4, pl_udm_pt5,\n",
        "                                       pl_udm_pt6, pl_udm_pt7, pl_udm_pt8, pl_udm_pt9, pl_udm_pt10,\n",
        "                                       pl_udm_pt11, pl_udm_pt12, pl_udm_pt13, pl_udm_pt14, pl_udm_pt15,\n",
        "                                       pl_udm_pt16, pl_udm_pt17, pl_udm_pt18, pl_udm_pt19, pl_udm_pt20])\n",
        "\n",
        "pl_udm_mosaic = pl_udm_ic.max()\n",
        "\n",
        "\n",
        "# Reclassified VIIRS flood map we exported at the end of module 6\n",
        "vfm = ee.Image(parent_directory + \"vfm_harmonized\")\n",
        "\n",
        "# Reclassified GFM Flood Map we exported at the end of module 6\n",
        "gfm = ee.Image(parent_directory + \"gfm_harmonized\")\n",
        "\n",
        "# HYDRAFloods Map that we exported at the end of module X\n",
        "hf = ee.Image(parent_directory + \"hydrafloods_harmonized\")\n",
        "\n",
        "# HYDROSAR Map that we exported at the end of Module 6\n",
        "hs = ee.Image(parent_directory + \"hydrosar_harmonized\")\n",
        "\n",
        "# Reclassified MCDWD Flood Map we exported at the end of module 6\n",
        "mcdwd = ee.Image(parent_directory + \"mcdwd_harmonized\")\n",
        "\n",
        "# Reclassified DSWx-HLS Flood Map we exported at the end of module 6\n",
        "dswxhls = ee.Image(parent_directory + \"dswxhls_harmonized\")\n",
        "\n",
        "# Reclassified DSWx-S1 Flood Map we exported at the end of module 6\n",
        "dswxs1 = ee.Image(parent_directory + \"dswxs1_harmonized\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_projection = vfm.projection().getInfo()[\"crs\"] # Get the common projection shared by all flood maps."
      ],
      "metadata": {
        "id": "si3BhIieVuOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Stratification\n",
        "\n",
        "We will conduct clustered stratified random sampling.\n",
        "\n",
        "We will cluster our point sampling to locations where all optical sensors used in this project (e.g. Planet, VIIRS, MODIS, and HLS) have an unobstructed view of the ground (i.e. where no optical sensors have clouds or are otherwise masked).\n",
        "\n",
        "We will conduct two stage stratified sampling. The first stage will be land cover, and the second stage will be flood vs. non flood."
      ],
      "metadata": {
        "id": "E9cXfx7lIPrZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 Part 1: Land Cover\n",
        "\n",
        "We will use Google's [Dynamic World](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_DYNAMICWORLD_V1) dataset to conduct stratification by land cover:"
      ],
      "metadata": {
        "id": "SvZ1DvMG06aH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dw = ee.ImageCollection(\"GOOGLE/DYNAMICWORLD/V1\")         # Get the Dynamic World dataset\n",
        "szn = ee.Date(doi).advance(-3, 'month')                   # Get the date 3 months prior to the date of interest\n",
        "\n",
        "dw_seasonal = dw.filterBounds(aoi).filterDate(szn, doi)   # Filter the Dynamic world dataset to the area of interest and to the time period between 3 months prior to the date of interest and the date of interest\n",
        "dw_redux = dw_seasonal.mode()                             # Use a mode temporal reducer to get the most often occurring land cover type for each pixel over the past three months\n",
        "dw_discrete = dw_redux.select('label')                    # select the discrete land cover label"
      ],
      "metadata": {
        "id": "g3BWCjSx0rLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dynamic World Visualization Parameters\n",
        "dwvp = {\n",
        "    'min': 0,\n",
        "    'max': 8,\n",
        "    'palette': ['419bdf', '397d49', '88b053', '7a87c6', 'e49635',   # 0 = blue            water\n",
        "                'dfc35a', 'c4281b', 'a59b8f', 'b39fe1']             # 1 = dark green      trees\n",
        "}                                                                   # 2 = light green     grass\n",
        "                                                                    # 3 = purple          flooded vegetation\n",
        "                                                                    # 4 = orange          crops\n",
        "                                                                    # 5 = yellow          shrub\n",
        "                                                                    # 6 = red             built\n",
        "                                                                    # 7 = gray            bare\n",
        "                                                                    # 8 = light purple    snow and ice"
      ],
      "metadata": {
        "id": "Z0ljJ3331jhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the land cover over the region of interest.\n",
        "Map = geemap.Map(center = (lat, lon), zoom = 6)\n",
        "Map.addLayer(dw_discrete, dwvp, 'Seasonal land cover')\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "daSeJgXf11zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_geom = aoi.geometry() # Get the geometry of the area of interest."
      ],
      "metadata": {
        "id": "izLfC8bxLK8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will print the percentage of the study area occupied by each land cover type."
      ],
      "metadata": {
        "id": "1JIhggLzLzci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "areaimg = ee.Image().pixelArea().addBands(dw_discrete)\n",
        "\n",
        "# USe the reduceRegion method to calculate the area occupied by each raster value of the dynamic world image\n",
        "dwgr = areaimg.reduceRegion(**{\n",
        "    'reducer': ee.Reducer.sum().group(**{\n",
        "        'groupField': 1,\n",
        "        'groupName': 'class'\n",
        "    }),\n",
        "    'geometry': final_geom,                     # Perform this calculation only over the area of interest\n",
        "    'scale': 30,                                # Do this calculation over a pixel size of 30 meters\n",
        "    'crs': my_projection,                       # Use the User-defined projection\n",
        "    'maxPixels': 1e10\n",
        "})\n",
        "\n",
        "pc_dict = dwgr.getInfo()                        # use the getInfo method to transform the above into a dictionary\n",
        "\n",
        "groups = pc_dict['groups']                      # get the groups key from the dictionary\n",
        "sum = 0\n",
        "\n",
        "for x in range(len(groups)):                           # Calculate the total area in the region of interest\n",
        "  sum += groups[x]['sum']\n",
        "\n",
        "water_percent = groups[0]['sum'] / sum * 100             # For each raster value, calculate the percentage it occupies of the study area\n",
        "trees_percent = groups[1]['sum'] / sum * 100\n",
        "grass_percent = groups[2]['sum'] / sum * 100\n",
        "flooded_veg_percent = groups[3]['sum'] / sum * 100\n",
        "crops_percent = groups[4]['sum'] / sum * 100\n",
        "shrub_percent = groups[5]['sum'] / sum * 100\n",
        "built_percent = groups[6]['sum'] / sum * 100\n",
        "bare_percent = groups[7]['sum'] / sum * 100\n",
        "snow_and_ice_percent = groups[8]['sum'] / sum * 100"
      ],
      "metadata": {
        "id": "qGsI0lT62h9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the outputs to the console\n",
        "print('Water occupies {0:0.2f} % of the area of interest'.format(water_percent))\n",
        "print('Trees occupies {0:0.2f} % of the area of interest'.format(trees_percent))\n",
        "print('Grass occupies {0:0.2f} % of the area of interest'.format(grass_percent))\n",
        "print('Flooded Vegetation occupies {0:0.2f} % of the area of interest'.format(flooded_veg_percent))\n",
        "print('Crops occupy {0:0.2f} % of the area of interest'.format(crops_percent))\n",
        "print('Shrub occupies {0:0.2f} % of the area of interest'.format(shrub_percent))\n",
        "print('Built-Up occupies {0:0.2f} % of the area of interest'.format(built_percent))\n",
        "print('Bare Ground occupies {0:0.2f} % of the area of interest'.format(bare_percent))\n",
        "print('Snow and Ice occupies {0:0.2f} % of the area of interest'.format(snow_and_ice_percent))"
      ],
      "metadata": {
        "id": "RpBQDD873lJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classes that occupy less than 5% of the area of interest and are not classes of interest (built-up and crops) will be aggregated into a background class.\n",
        "\n",
        "In this case, water, flooded vegetation, shrubs, bare ground, and snow and ice will be included in the background class"
      ],
      "metadata": {
        "id": "qeIurC3UUDKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define each land cover class\n",
        "water = dw_discrete.eq(0)\n",
        "trees = dw_discrete.eq(1)\n",
        "grass = dw_discrete.eq(2)\n",
        "flooded_veg = dw_discrete.eq(3)\n",
        "crops = dw_discrete.eq(4)\n",
        "shrub = dw_discrete.eq(5)\n",
        "built = dw_discrete.eq(6)\n",
        "bare = dw_discrete.eq(7)\n",
        "snow = dw_discrete.eq(8)\n",
        "\n",
        "# Define the background class\n",
        "background = dw_discrete.eq(3).Or(dw_discrete.eq(5)).Or(dw_discrete.eq(7)).Or(dw_discrete.eq(8))"
      ],
      "metadata": {
        "id": "JWC77eb27TF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the landcover map and the background class to the map\n",
        "Map = geemap.Map(center = (lat, lon), zoom = 7)\n",
        "Map.addLayer(dw_discrete, dwvp, 'Dynamic World')\n",
        "Map.addLayer(background, {}, 'Background')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "L4zjULz-VFKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 Part 2: Flood vs Non-flood"
      ],
      "metadata": {
        "id": "xXUNJHlLVXL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned above, our second stage for stratification will be flood vs. nonflood. Here we define a pixel as flooded if the GFM product identified it as water AND the Joint Research Center Map identified the pixel as nonwater. You can see read the JRC map documentation [here](https://storage.googleapis.com/global-surface-water/downloads_ancillary/DataUsersGuidev2021.pdf)."
      ],
      "metadata": {
        "id": "hZVXxh60MDw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will define product water using the GFM map.\n",
        "product_water = gfm.eq(1)"
      ],
      "metadata": {
        "id": "kLyRVY2x4YG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the Yearly History Global Surface Water map produced by the Joint Research Center\n",
        "jrc = ee.ImageCollection(\"JRC/GSW1_4/YearlyHistory\").filterDate(\"1985-01-01\", doi)\n",
        "\n",
        "# Get the most recent Joint Research Center map, which happens to be from 2021.\n",
        "jrc_2021 = ee.Image(jrc.toList(50).get(-1))"
      ],
      "metadata": {
        "id": "EGNR6Jf64xbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jrc_unmasked = jrc_2021.unmask()         # Unmask the JRC image\n",
        "jrc_nonwater = jrc_unmasked.lt(2)        # Get the nonwater pixels (excludes permanent water and seasonal water)\n",
        "normal_nonwater = jrc_nonwater.eq(1)\n",
        "\n",
        "flood = product_water.And(normal_nonwater)  # Define flood as product water and JRC_nonwater"
      ],
      "metadata": {
        "id": "alQIVmS95HhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the flood strata to the map.\n",
        "Map = geemap.Map(center = (lat, lon), zoom = 7)\n",
        "Map.addLayer(flood)\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "3qWjNoqLSBJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 Part 3: Cloud vs noncloud"
      ],
      "metadata": {
        "id": "0pDN90pC5VBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some visualization parameters for our Planet imagery\n",
        "pl_trucolor = {\n",
        "    'bands': ['b6', 'b4', 'b2'],\n",
        "    'min': 2000,\n",
        "    'max': 18000\n",
        "}\n",
        "\n",
        "# Define some visualization parameters for our Usable Data Mask (UDM)\n",
        "pl_udm_vp = {\n",
        "    'bands': ['b1'],\n",
        "    'min': 0,\n",
        "    'max': 1\n",
        "}"
      ],
      "metadata": {
        "id": "1ouvThVn5UD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the Layer to the Map\n",
        "Map = geemap.Map(center = (lat, lon), zoom = 7)\n",
        "Map.addLayer(pl_mos, pl_trucolor, 'Planet Truecolor Mosaic')\n",
        "Map.addLayer(pl_udm_mosaic, pl_udm_vp, 'Planet UDM')\n",
        "#Map.addLayer(pl_udm_pt2, pl_udm_vp, 'Planet UDM2')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "0mAawPGG5aNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the mask from each flood product. Earlier in Module 3, we set the mask value for each map to be equal to 2.\n",
        "vfm_mask = vfm.eq(2)\n",
        "gfm_mask = gfm.eq(2)\n",
        "mcdwd_mask = mcdwd.eq(2)\n",
        "dswxhls_mask = dswxhls.eq(2)\n",
        "dswxs1_mask = dswxs1.eq(2)\n",
        "\n",
        "# Unmask the Planet UDM\n",
        "pl_udm_unm = pl_udm_mosaic.unmask()\n",
        "\n",
        "# Extract pixels where the Planet image has unclear observtions\n",
        "pl_unclear = pl_udm_unm.select(['b1']).eq(0)\n",
        "\n",
        "# Extract the pixels where the planet imagery or any flood product has an unclear observation of the ground. This will be our final mask.\n",
        "cloud_mask = pl_unclear.eq(1).Or(vfm_mask.eq(1)).Or(gfm_mask.eq(1)).Or(mcdwd_mask.eq(1)).Or(dswxhls_mask.eq(1)).Or(dswxs1_mask.eq(1))\n",
        "final_mask = cloud_mask.eq(0)"
      ],
      "metadata": {
        "id": "TIfRaf115cW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the final mask and the planet mosaic to the map.\n",
        "Map = geemap.Map(center = (lat, lon), zoom = 10)\n",
        "Map.addLayer(pl_mos, pl_trucolor, 'Planet Truecolor Mosaic')\n",
        "Map.addLayer(final_mask, {}, 'Final Mask')\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "4jI8V7dA6nJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Conduct Stratified Sampling"
      ],
      "metadata": {
        "id": "5NLqBZjC651j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Olofsson et al approximates the sample size n as follows:\n",
        "\n",
        "$n = (\\frac{\\sum W_i S_i}{S(O)})^2 $\n",
        "\n",
        "where $W_i$ is the mapped proportion of area of class i, $S_i$ is the standard deviation of stratum i, and S(O) is the standard error of the estimated overall accuracy we would like to achieve."
      ],
      "metadata": {
        "id": "IDCGNSHhQFnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 Part 1: Construct Each Strata"
      ],
      "metadata": {
        "id": "s4pyQ6rgBRE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flooded = flood.eq(1)\n",
        "nonflooded = flood.eq(0)\n",
        "\n",
        "cloudy = final_mask.eq(0)\n",
        "noncloudy = final_mask.eq(1)\n",
        "\n",
        "# Construct each strata, one for each permutation of flooded/not and landcover class.\n",
        "# For each strata, we will only use pixels where all flood products and the planet imagery are not masked.\n",
        "# Strata may have to be changed based on definition of background class\n",
        "\n",
        "s0 = nonflooded.And(background).And(final_mask.eq(1))\n",
        "s1 = flooded.And(background).And(final_mask.eq(1))\n",
        "s2 = nonflooded.And(water).And(final_mask.eq(1))\n",
        "s3 = flooded.And(water).And(final_mask.eq(1))\n",
        "s4 = nonflooded.And(trees).And(final_mask.eq(1))\n",
        "s5 = flooded.And(trees).And(final_mask.eq(1))\n",
        "s6 = nonflooded.And(grass).And(final_mask.eq(1))\n",
        "s7 = flooded.And(grass).And(final_mask.eq(1))\n",
        "s8 = nonflooded.And(crops).And(final_mask.eq(1))\n",
        "s9 = flooded.And(crops).And(final_mask.eq(1))\n",
        "s10 = nonflooded.And(built).And(final_mask.eq(1))\n",
        "s11 = flooded.And(built).And(final_mask.eq(1))"
      ],
      "metadata": {
        "id": "d985TRtE6yE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the mask of the Dynamic World Mask\n",
        "dw_masked = dw_discrete.updateMask(final_mask)"
      ],
      "metadata": {
        "id": "AIjGfmFzYU41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_img = flood.updateMask(final_mask)                              # Get a dummy image in the EPSG 32633 projection\n",
        "\n",
        "# Manually create the strata image using the earth engine \"where\" method\n",
        "strata = dummy_img.where(s0, ee.Image(0))\n",
        "strata_v2 = strata.where(s1, ee.Image(1))\n",
        "strata_v3 = strata_v2.where(s2, ee.Image(2))\n",
        "strata_v4 = strata_v3.where(s3, ee.Image(3))\n",
        "strata_v5 = strata_v4.where(s4, ee.Image(4))\n",
        "strata_v6 = strata_v5.where(s5, ee.Image(5))\n",
        "strata_v7 = strata_v6.where(s6, ee.Image(6))\n",
        "strata_v8 = strata_v7.where(s7, ee.Image(7))\n",
        "strata_v9 = strata_v8.where(s8, ee.Image(8))\n",
        "strata_v10 = strata_v9.where(s9, ee.Image(9))\n",
        "strata_v11 = strata_v10.where(s10, ee.Image(10))\n",
        "strata_v12 = strata_v11.where(s11, ee.Image(11))"
      ],
      "metadata": {
        "id": "Q_n8Fmtx9-9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strata_v13 = strata_v12.updateMask(final_mask)"
      ],
      "metadata": {
        "id": "EerC_irkQmhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create visualization parameters for the strata\n",
        "strata_vp = {\n",
        "    'min': 0,\n",
        "    'max': 11,\n",
        "    'palette': ['d3d3d3', 'a9a9a9', 'add8e6', '00008b', '90ee90', '013220', 'ffffed',\n",
        "                '8b8000', 'ffd580', 'ff8c00', 'ff474c', '8b0000']\n",
        "}"
      ],
      "metadata": {
        "id": "WmWYaCktZjvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map(center = (lat, lon), zoom = 7)\n",
        "\n",
        "Map.addLayer(strata_v13, strata_vp, 'Strata')\n",
        "Map.addLayer(dw_masked, dwvp, 'Dynamic World')\n",
        "Map.addLayer(final_mask)\n",
        "Map\n",
        "\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "s5v7Dzvgacon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 Part 2: Calculate $W_i$ for Each Strata Class"
      ],
      "metadata": {
        "id": "_CsbItQwBXBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the area occupied by each stratum, similar to what we did with the land cover map.\n",
        "strata_areaimg = ee.Image().pixelArea().addBands(strata_v13)\n",
        "\n",
        "strata_redux = strata_areaimg.reduceRegion(**{\n",
        "    'reducer': ee.Reducer.sum().group(**{\n",
        "        'groupField': 1,\n",
        "        'groupName': 'class'\n",
        "    }),\n",
        "    'geometry': final_geom,\n",
        "    'crs': my_projection,\n",
        "    'scale': 30,\n",
        "    'maxPixels': 1e10\n",
        "})"
      ],
      "metadata": {
        "id": "2SeqX9GXGSpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, no pixels appear for class 11, indicating that no pixel in the built-up class was flooded"
      ],
      "metadata": {
        "id": "ckOB6bNceqQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strata_groups = strata_redux.getInfo()['groups']\n",
        "\n",
        "pixel_sum = 0\n",
        "\n",
        "for g in range(len(strata_groups)):\n",
        "  pixel_sum += strata_groups[g]['sum']\n",
        "\n",
        "w0 = strata_groups[0]['sum'] / pixel_sum\n",
        "w1 = strata_groups[1]['sum'] / pixel_sum\n",
        "w2 = strata_groups[2]['sum'] / pixel_sum\n",
        "w3 = strata_groups[3]['sum'] / pixel_sum\n",
        "w4 = strata_groups[4]['sum'] / pixel_sum\n",
        "w5 = strata_groups[5]['sum'] / pixel_sum\n",
        "w6 = strata_groups[6]['sum'] / pixel_sum\n",
        "w7 = strata_groups[7]['sum'] / pixel_sum\n",
        "w8 = strata_groups[8]['sum'] / pixel_sum\n",
        "w9 = strata_groups[9]['sum'] / pixel_sum\n",
        "w10 = strata_groups[10]['sum'] / pixel_sum\n",
        "w11 = 0\n",
        "\n",
        "print('Percent of pixels occupied by Strata 0 (Background class and nonflooded): {0:0.1f}'.format(w0*100))\n",
        "print('Percent of pixels occupied by Strata 1 (Background class and flooded): {0:0.1f}'.format(w1*100))\n",
        "print('Percent of pixels occupied by Strata 2 (Water and nonflooded): {0:0.1f}'.format(w2*100))\n",
        "print('Percent of pixels occupied by Strata 3 (Water and flooded): {0:0.1f}'.format(w3*100))\n",
        "print('Percent of pixels occupied by Strata 4 (Trees and nonflooded): {0:0.1f}'.format(w4*100))\n",
        "print('Percent of pixels occupied by Strata 5 (Trees and flooded): {0:0.3f}'.format(w5*100))\n",
        "print('Percent of pixels occupied by Strata 6 (Grass and nonflooded): {0:0.1f}'.format(w6*100))\n",
        "print('Percent of pixels occupied by Strata 7 (Grass and flooded): {0:0.2f}'.format(w7*100))\n",
        "print('Percent of pixels occupied by Strata 8 (Crops and nonflooded): {0:0.1f}'.format(w8*100))\n",
        "print('Percent of pixels occupied by Strata 9 (Crops and flooded): {0:0.4f}'.format(w9*100))\n",
        "print('Percent of pixels occupied by Strata 10 (Built and nonflooded): {0:0.2f}'.format(w10*100))\n",
        "print('Percent of pixels occupied by Strata 11 (Built and flooded): {0:0.5f}'.format(w11*100))"
      ],
      "metadata": {
        "id": "pNrG1yxEGSme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 Part 3: Calculate $S_i$ for Each Strata Class"
      ],
      "metadata": {
        "id": "ZMtjg757BdwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know the area occupied by each Class, we will now define the user's accuracy for each class. The user's accuracy for the flooded classed were calculated as the mean of the user's accuracy for the water class reported by various flood products. the user's accuracy for the nonflooded classes was determined through the reports of the VFM product's performance. No other flood product reported the user's accuracy for the nonwater class."
      ],
      "metadata": {
        "id": "Wlpz8j4e4KL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "u_water = 0.89448485408\n",
        "u_nonwater = 0.98517"
      ],
      "metadata": {
        "id": "wpy8N5SqGSgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u0 = u_nonwater  # User's Accuracy for Strata 0\n",
        "u1 = u_water     # User's accuracy for Strata 1\n",
        "u2 = u_nonwater     # User's Accuracy for Strata 2\n",
        "u3 = u_water  # User's Accuracy for Strata 3\n",
        "u4 = u_nonwater     # User's Accuracy for Strata 4\n",
        "u5 = u_water  # User's Accuracy for Strata 5\n",
        "u6 = u_nonwater     # User's Accuracy for Strata 6\n",
        "u7 = u_water  # User's Accuracy for Strata 7\n",
        "u8 = u_nonwater     # User's Accuracy for Strata 8\n",
        "u9 = u_water  # User's Accuracy for Strata 9\n",
        "u10 = u_nonwater    # User's Accuracy for Strata 10\n",
        "#u11 = u_water # User's Accuracy for Strata 11"
      ],
      "metadata": {
        "id": "EqM0S3B5GSdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will define a function to convert the user's accuracy of a particular class to the standard deviation for that class"
      ],
      "metadata": {
        "id": "L8x8VpIK5YSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stdev(ui):\n",
        "  term2 = 1 - ui\n",
        "  term = ui * term2\n",
        "  si = np.sqrt(term)\n",
        "  return si"
      ],
      "metadata": {
        "id": "vhKdSVtwGSaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the standard deviation function over each class\n",
        "sd0 = stdev(u0)\n",
        "sd1 = stdev(u1)\n",
        "sd2 = stdev(u2)\n",
        "sd3 = stdev(u3)\n",
        "sd4 = stdev(u4)\n",
        "sd5 = stdev(u5)\n",
        "sd6 = stdev(u6)\n",
        "sd7 = stdev(u7)\n",
        "sd8 = stdev(u8)\n",
        "sd9 = stdev(u9)\n",
        "sd10 = stdev(u10)\n",
        "#sd11 = stdev(u11)"
      ],
      "metadata": {
        "id": "bCzXbFGsGSW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p0 = w0 * sd0\n",
        "p1 = w1 * sd1\n",
        "p2 = w2 * sd2\n",
        "p3 = w3 * sd3\n",
        "p4 = w4 * sd4\n",
        "p5 = w5 * sd5\n",
        "p6 = w6 * sd6\n",
        "p7 = w7 * sd7\n",
        "p8 = w8 * sd8\n",
        "p9 = w9 * sd9\n",
        "p10 = w10 * sd10\n",
        "#p11 = w11 * sd11"
      ],
      "metadata": {
        "id": "T03r3kguGSTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "psum = p0 + p1 + p2 + p3 + p4 + p5 + p6 + p8 + p9 + p10 #+ p11 #+ p12 + p13 + p14 + p15 + p16 + p17 + p18 + p19 + p20\n",
        "psum"
      ],
      "metadata": {
        "id": "WfuXxjAEJzxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error0 = 1e-3\n",
        "error1 = 2.5e-3\n",
        "error2 = 5e-3\n",
        "error3 = 7e-3\n",
        "error4 = 1e-2\n",
        "error5 = 5e-2"
      ],
      "metadata": {
        "id": "Kjpxr2ARJzuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4 Part 4: Estimate S(O).\n",
        "\n",
        "We will use several estimates for S(O)"
      ],
      "metadata": {
        "id": "sB1XnuUDBl93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Size Estimation Function\n",
        "def sse(error):\n",
        "  return np.round((psum/error)**2)"
      ],
      "metadata": {
        "id": "8C5uhvicJzsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss0 = sse(error0)\n",
        "ss1 = sse(error1)\n",
        "ss2 = sse(error2)\n",
        "ss3 = sse(error3)\n",
        "ss4 = sse(error4)\n",
        "ss5 = sse(error5)"
      ],
      "metadata": {
        "id": "06LKftRwJzqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using a standard error of {}, our total sample size would be {}\".format(error0, ss0))\n",
        "print(\"Using a standard error of {}, our total sample size would be {}\".format(error1, ss1))\n",
        "print(\"Using a standard error of {}, our total sample size would be {}\".format(error2, ss2))\n",
        "print(\"Using a standard error of {}, our total sample size would be {}\".format(error3, ss3))\n",
        "print(\"Using a standard error of {}, our total sample size would be {}\".format(error4, ss4))"
      ],
      "metadata": {
        "id": "7IB-2Zt6Jznx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 Part 5: Determine Allocation Strategy"
      ],
      "metadata": {
        "id": "D5D5pGjKB_tQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use the sample size of 2,354. This is the total number of points we will use in our study area. Now we have to decide how to distribute these points within our study area.\n",
        "\n",
        "One option is to use equal allocation, where we assign an equal number of points across our strata.\n",
        "\n",
        "Another option is to use proportional allocation, where we assign a number of points to each strata proportional to the area occupied by that strata\n",
        "\n",
        "A third option is to assign a certain number of points to each strata, and then assign the remainder of points according to a proportional distribution.\n",
        "\n",
        "The above allocation strategies are expanded upon in Olofsson et al 2014. Different allocation strategies may bias the results towards either precision or recall. Following Olofsson et al 2014, we will use the third option of allocation to balance between precision and recall (See references)."
      ],
      "metadata": {
        "id": "BrzyhBfrJ_y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 2354\n",
        "num_classes = 11"
      ],
      "metadata": {
        "id": "DU6bRxQwJ6zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equal = num_samples / num_classes\n",
        "equal"
      ],
      "metadata": {
        "id": "PVPv788mJ6wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above is the number of samples each class would get if we assigned an equal number of samples to each strata. We want to employ a hybrid strategy where we assign each class a minimum number of points, then assign the remaining samples proportional to the area occupied by the strata. We will select the minimum number of samples as half the number of the equal number of samples"
      ],
      "metadata": {
        "id": "fNbxO3M8KSSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min = np.floor(equal / 2)\n",
        "min"
      ],
      "metadata": {
        "id": "chW4ENopJ6tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_samples = num_samples - (min * 11)\n",
        "remaining_samples"
      ],
      "metadata": {
        "id": "18eDo9EiJ6rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min * 11"
      ],
      "metadata": {
        "id": "QJdfpM4HKzVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n0 = np.float64(min + np.round(w0 * remaining_samples))\n",
        "n1 = np.float64(min + np.round(w1 * remaining_samples))\n",
        "n2 = np.float64(min + np.round(w2 * remaining_samples))\n",
        "n3 = np.float64(min + np.round(w3 * remaining_samples))\n",
        "n4 = np.float64(min + np.round(w4 * remaining_samples))\n",
        "n5 = np.float64(min + np.round(w5 * remaining_samples))\n",
        "n6 = np.float64(min + np.round(w6 * remaining_samples))\n",
        "n7 = np.float64(min + np.round(w7 * remaining_samples))\n",
        "n8 = np.float64(min + np.round(w8 * remaining_samples))\n",
        "n9 = np.float64(min + np.round(w9 * remaining_samples))\n",
        "n10 = np.float64(min + np.round(w10 * remaining_samples))\n",
        "#n11 = np.float64(min + np.round(w11 * remaining_samples))"
      ],
      "metadata": {
        "id": "0AB65z44JzlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The sample size for Class 0 is\", n0)\n",
        "print(\"The sample size for Class 1 is\", n1)\n",
        "print(\"The sample size for Class 2 is\", n2)\n",
        "print(\"The sample size for Class 3 is\", n3)\n",
        "print(\"The sample size for Class 4 is\", n4)\n",
        "print(\"The sample size for Class 5 is\", n5)\n",
        "print(\"The sample size for Class 6 is\", n6)\n",
        "print(\"The sample size for Class 7 is\", n7)\n",
        "print(\"The sample size for Class 8 is\", n8)\n",
        "print(\"The sample size for Class 9 is\", n9)\n",
        "print(\"The sample size for Class 10 is\", n10)"
      ],
      "metadata": {
        "id": "qT6D-B9bLWXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n0 + n1 + n2 + n3 + n4 + n5 + n6 + n7 + n8 + n9 + n10 #+ n11"
      ],
      "metadata": {
        "id": "v9wjxzFbLWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples"
      ],
      "metadata": {
        "id": "f3ZJ-UgHLWRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of class values and class sample sizes to be used in the next code cell\n",
        "class_values =  ee.List([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])#, 11])\n",
        "\n",
        "class_points = [n0, n1, n2, n3, n4, n5, n6, n7, n8, n9, n10]#n11]"
      ],
      "metadata": {
        "id": "3mps1D7BL8Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Earth Engine .stratifiedSample method\n",
        "strat_sample = strata_v13.stratifiedSample(\n",
        "    region = final_geom,\n",
        "    numPoints=ee.Number(0),        # Dummy value which will be overridden by classValues and ClassPoints\n",
        "    classValues = class_values,\n",
        "    classPoints = class_points,\n",
        "    geometries=True,               # set the flag to true so each point has an associated geometry\n",
        "    scale=30,\n",
        "    projection=my_projection\n",
        ")"
      ],
      "metadata": {
        "id": "3920UloeLWOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wawa_vp = {\n",
        "    'min': 0,\n",
        "    'max': 2,\n",
        "    'palette': ['000000', 'add8e6', 'FFFFFF']\n",
        "}"
      ],
      "metadata": {
        "id": "Ej9o3DGws2W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map(center = (lat, lon), zoom = 7)\n",
        "\n",
        "\n",
        "Map.addLayer(strat_sample, {}, 'Stratified Sample')\n",
        "#Map.addLayer(utm_zones, {}, 'UTM zones')\n",
        "Map.addLayer(pl_mos)\n",
        "Map.addLayer(final_geom, {}, 'Final Geom')\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "metadata": {
        "id": "s9nOatnoLWMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the Stratified Sample into a CEO-friendly format"
      ],
      "metadata": {
        "id": "Rbw2kpKhC9g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have our stratified sample. But we want to collect our reference data in a platform known as Collect Earth Online, so let's use Python to convert our stratified sample into a CEO-friendly format"
      ],
      "metadata": {
        "id": "hI2AOFGzDCjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the point collection to Google Drive\n",
        "geemap.ee_export_vector_to_drive(strat_sample, description='strat_sample_'+flood_event_desc, fileFormat = 'CSV')"
      ],
      "metadata": {
        "id": "7ozGOhTbWdeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/') # Mount Google Drive"
      ],
      "metadata": {
        "id": "1zyNfwLdLWJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive               # Choose the My Drive Folder"
      ],
      "metadata": {
        "id": "yQMrwUU1X6Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls strat_sample*.csv           # list files starting in strat_sample"
      ],
      "metadata": {
        "id": "vyafhM2TX_L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "strat_sample = pd.read_csv('strat_sample'+flood_event_desc+'.csv')\n",
        "strat_sample.head()"
      ],
      "metadata": {
        "id": "uyUwjV_AYCtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = len(strat_sample)"
      ],
      "metadata": {
        "id": "xSmWcYdDYQ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t92Gl0aOC8mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract latitudes and longitudes from the stratified sample\n",
        "geomes = strat_sample[\".geo\"]\n",
        "substring = geomes[0][48:]\n",
        "substring_split = substring.split(',')\n",
        "longitude = substring_split[0]\n",
        "latitude_rough = substring_split[1]\n",
        "latitude = latitude_rough.split(']')[0]\n",
        "print('latitude', latitude)\n",
        "print('longitude', longitude)"
      ],
      "metadata": {
        "id": "hSkdH1rXYZdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Write the CEO-friendly version to a CSV\n",
        "filename = 'upload_ready_strat_sample.csv'\n",
        "\n",
        "with open(filename, 'w') as csvfile:\n",
        "  fields = ['PLOTID', 'LON', 'LAT']\n",
        "\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "\n",
        "  csvwriter.writerow(fields)\n",
        "\n",
        "  for j in range(num_rows):\n",
        "    geometries = strat_sample[\".geo\"]\n",
        "    geom_of_int = geometries[j]\n",
        "    substring = geom_of_int[48:]\n",
        "    substring_split = substring.split(',')\n",
        "    longitude = substring_split[0]\n",
        "    latitude_rough = substring_split[1]\n",
        "    latitude = latitude_rough.split(']')[0]\n",
        "\n",
        "    my_row = [str(j), longitude, latitude]\n",
        "    csvwriter.writerow(my_row)"
      ],
      "metadata": {
        "id": "QGJ2ivQrYNbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls UPLOAD_RDY*"
      ],
      "metadata": {
        "id": "gB2UtCpvZz8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, download the \"UPLOAD_RDY\" CSV file from Google Drive. Proceed to Module_5"
      ],
      "metadata": {
        "id": "6NMs5Ntj98w6"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}