{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SERVIR/flood_mapping_intercomparison/blob/main/notebooks/Module_8_Resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this module, we will resample all of our products to a common pixel size. Since 4 of our 7 products already have a pixel size of 30 meters, we will use 30 meters as our common pixel size.\n",
        "\n",
        "To accomplish this, we will use the gdal.Warp method. gdal.Warp takes the following optional arguments (among others):\n",
        "* xRes\n",
        "* yRes\n",
        "* resampleAlg\n",
        "\n",
        "Since we want to create square pixels measuring 30 meters by 30 meters in size, we will set xRes and yRes to both equal 30. The resampleAlg argument determines how the input map will go about determining the pixel value for each output 30x30m pixel. There are several options for this argument. In this case, we will use 'near', which is the nearest neighbor resampling algorithm. We will accomplish this by resampling the already harmonized maps that were a result of our processing in Module 3.\n",
        "\n",
        "For more information on the different resampling algorithms available in GDAL, see [this page](https://gdal.org/en/stable/programs/gdalwarp.html) and scroll down to \"-r resampling_method\"."
      ],
      "metadata": {
        "id": "Bd4ryEn2lszm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxb7X-hvMnLP"
      },
      "source": [
        "# Step 1: Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n07orLu6Mpt1"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geemap\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "from osgeo import gdal\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from osgeo import gdal, osr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6y1FZ23uqkR"
      },
      "source": [
        "# MODIFIABLE VARIABLE ALERT\n",
        "\n",
        "Change the variables below to match the needs of your case study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoEql5pmrtiC"
      },
      "outputs": [],
      "source": [
        "# Google Earth Engine folder. This should end in a slash.\n",
        "my_gee_folder = \"users/mickymags/sep_arkansas/\"\n",
        "\n",
        "# Google Earth Engine Project name\n",
        "my_gee_project = 'servir-sco-assets'\n",
        "\n",
        "# Google Drive Folder where your flood maps are located. This should end in a slash.\n",
        "my_Gdrive_folder = \"/content/drive/MyDrive/Flood_Intercomparison/Case_Studies/sep/sep_arkansas/\"\n",
        "\n",
        "# Flood event description. This can be whatever you want it to be\n",
        "flood_event_desc = 'sep_arkansas'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate and initialize Earth Engine. This will kick off a pop-up window that you must click through.\n",
        "ee.Authenticate()\n",
        "\n",
        "ee.Initialize(project=my_gee_project)"
      ],
      "metadata": {
        "id": "wwW8Ym9BTBEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyLO0Vj2u0Py"
      },
      "outputs": [],
      "source": [
        "aoi = ee.FeatureCollection(my_gee_folder + \"aoi\")\n",
        "roi = aoi.geometry()\n",
        "aoi_centroid = aoi.geometry().centroid()             # Get the center of the AOI\n",
        "lon = aoi_centroid.coordinates().get(0).getInfo()    # Extract the longitude from the centroid\n",
        "lat = aoi_centroid.coordinates().get(1).getInfo()    # Extract the latitude from the centroid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfFuTWdUMixD"
      },
      "source": [
        "# Step 2: Resample GFM, MCDWD, and VFM products (and maybe HYDROSAR)\n",
        "\n",
        "In order to run object extraction statistics, we must have all products in a common projection. Thus, we will use gdal.Warp to resample these products to 30 meters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "KSeP-QI_nbNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the Google Drive folder you defined in the MODIFIABLE VARIABLE section\n",
        "os.chdir(my_Gdrive_folder)"
      ],
      "metadata": {
        "id": "XmqXXoodnlGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 Part 1: GFM"
      ],
      "metadata": {
        "id": "edVXR6I0pxtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('GFM') # Choose the GFM directory"
      ],
      "metadata": {
        "id": "ff32kA6-nrIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infile = glob.glob('harmonized_gfm*')[0] # define the infile, which will be the input"
      ],
      "metadata": {
        "id": "B1LrqAL4ntrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outfile = 'gfm_resampled_' + flood_event_desc + '.tif' # define the outfile string, which will be the output"
      ],
      "metadata": {
        "id": "FIdKeS5mn2gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = gdal.Info(infile)        # Get the info from the inflie\n",
        "find = info.find('Data axis')   # find the index of the information containing the projection\n",
        "proj = info[find-8:find-3]      # slice the info string to extract projection EPSG code\n",
        "my_proj = 'EPSG:'+proj          # manipulaate EPSG code for formatting\n",
        "print(my_proj)                  # print the projection"
      ],
      "metadata": {
        "id": "laRB8fskoZsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample the input file to 30x30m and write data to the output file\n",
        "gdal.Warp(outfile, infile, dstSRS=my_proj, resampleAlg='near', xRes=30, yRes=30)"
      ],
      "metadata": {
        "id": "0BpQ54SdoF1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 Part 2: MCDWD"
      ],
      "metadata": {
        "id": "-20SlKoIp1Pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's repeat the above process for the MCDWD product"
      ],
      "metadata": {
        "id": "cJWkANcMgXUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../MCDWD')"
      ],
      "metadata": {
        "id": "YjwQxu9fp5gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file\n",
        "mcdwd_infile = infile = glob.glob('harmonized_mcd*')[0]"
      ],
      "metadata": {
        "id": "5wQp1yuPp8HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output file\n",
        "mcdwd_outfile = 'mcdwd_intermediate_' + flood_event_desc + '.tif'"
      ],
      "metadata": {
        "id": "UKtsEhiYqEmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample infile to 30m x 30m at write it to the output file\n",
        "gdal.Warp(mcdwd_outfile, mcdwd_infile, dstSRS=my_proj, resampleAlg='near', xRes=30, yRes=30)"
      ],
      "metadata": {
        "id": "rdpyR30MqJP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inter_mcdwd = mcdwd_outfile                               # Define intermediate file path\n",
        "final_mcdwd = f'mcdwd_resampled_{flood_event_desc}.tif'   # Define string for final output file path\n",
        "vector_mcdwd = glob.glob('drive_export*')[0]              # Define file path for area of interest"
      ],
      "metadata": {
        "id": "qSiO-WUbdk6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clip the intermediate file to the area of interest,\n",
        "gdal.Warp(\n",
        "    final_mcdwd,                   # output\n",
        "    inter_mcdwd,                   # input\n",
        "    cutlineDSName=vector_mcdwd,    # area of interest input\n",
        "    cropToCutline=True,            # boolean controlling clipping\n",
        "    dstNodata = 2                  # value to use for no-data pixels\n",
        ")"
      ],
      "metadata": {
        "id": "o6qssIWtd_kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 Part 3: VFM\n",
        "\n",
        "Repeat the above steps for the VFM product"
      ],
      "metadata": {
        "id": "iQtXx68Yp26z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../VFM') # Navigate to the VFM subdirectory"
      ],
      "metadata": {
        "id": "PAqMesUEpru2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vfm_infile = infile = glob.glob('harmonized_vfm*')[0]          # Input File"
      ],
      "metadata": {
        "id": "BtaDcvGOqUqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vfm_outfile = 'vfm_intermediate_' + flood_event_desc + '.tif'  # Output File"
      ],
      "metadata": {
        "id": "J0nTMVTz52cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample the input file to 30m x 30m and write to the output file\n",
        "gdal.Warp(vfm_outfile, vfm_infile, dstSRS=my_proj, resampleAlg='near', xRes=30, yRes=30)"
      ],
      "metadata": {
        "id": "QDaPLTnz6Bh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inter_vfm = vfm_outfile                                # Intermediate file\n",
        "final_vfm = f'vfm_resampled_{flood_event_desc}.tif'    # Final output file\n",
        "vector_vfm = glob.glob('drive_export*')[0]             # file path to the area of interest"
      ],
      "metadata": {
        "id": "mkFYMwNjd2K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warp output file\n",
        "gdal.Warp(\n",
        "    final_vfm,                   # Output\n",
        "    inter_vfm,                   # Input\n",
        "    cutlineDSName=vector_vfm,    # Area of interest\n",
        "    cropToCutline=True,          # boolean controlling whether or not to clip\n",
        "    dstNodata = 2                # value to use for no-data pixels\n",
        ")"
      ],
      "metadata": {
        "id": "JdDPOdA4eARl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 Part 4: HYDROSAR"
      ],
      "metadata": {
        "id": "dTC0sL2Dk7sE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, HYDROSAR will not have a pixel size of 30 meters. If it does not, we will undergo the same workflow we did for VFM, GFM, and MCDWD. Let's check the pixel size of HYDROSAR"
      ],
      "metadata": {
        "id": "UM3JoM8mk-m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('../HYDROSAR')    # choose the HYDROSAR directory"
      ],
      "metadata": {
        "id": "c5nyy1zDSeVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hydrosar_infile = infile = glob.glob('harmonized_hydrosar*')[0]  # Define the path to the HYDROSAR input file"
      ],
      "metadata": {
        "id": "KhnwETCxSfha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the HYDROSAR input file\n",
        "hydrosar_file = gdal.Open(hydrosar_infile)\n",
        "\n",
        "# get the pixel size of hydrafloods\n",
        "hydrosar_pixel_size = hydrosar_file.GetGeoTransform()[1]\n",
        "\n",
        "# Ask the computer to tell us whether or not we need to reproject HYDROSAR\n",
        "if hydrosar_pixel_size == 30:\n",
        "  print(\"HYDROSAR has a pixel size of 30 meters. Skip to step 3.\")\n",
        "else:\n",
        "  print(\"HYDROSAR has a pixel size slightly different than 30 meters. Continue running the code below.\")"
      ],
      "metadata": {
        "id": "GciLRyYPlXeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hydrosar output file\n",
        "hydrosar_outfile = 'hydrosar_resampled_' + flood_event_desc + '.tif'"
      ],
      "metadata": {
        "id": "8Vv3Mqd6mF5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample the input file to 30m x 30m and write to the output file\n",
        "gdal.Warp(hydrosar_outfile, hydrosar_infile, dstSRS=my_proj, resampleAlg='near', xRes=30, yRes=30)"
      ],
      "metadata": {
        "id": "VXtlYtUTebx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (OPTIONAL) Step 3: Exporting to Google Earth Engine"
      ],
      "metadata": {
        "id": "8Z7KFMKmsk5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now all of our resampled flood maps are available in the Google Drive folder we designated at the beginning of this notebook. If you would like to run module 9, you must upload the resampled flood maps to Google Earth Engine. When doing so, make sure to change the pyramiding policy to Mode. You should upload all of the harmonized maps to Google Earth Engine in the same folder and with the name of \"x_harmonized\" (i.e. dswxhls_harmonized, gfm_harmonized)"
      ],
      "metadata": {
        "id": "I7lj9KxU_BQU"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}